#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ê®°ÊùøÊèíÂÖ•ÊúçÂä°ÔºöAIÊô∫ËÉΩÂêàÂπ∂ÂéüÂßãÊñáÊ°£‰∏éÊ®°ÊùøJSON
"""

import os
import json
import logging
import traceback
import hashlib
import tempfile
from datetime import datetime
from typing import Dict, Any, Optional, Union
from pathlib import Path
import argparse

from docx import Document
from docx.shared import Inches, Pt
from docx.enum.text import WD_PARAGRAPH_ALIGNMENT
from openai import OpenAI
import fitz  # PyMuPDF
from docx import Document as DocxDocument

# ÈÖçÁΩÆÊó•ÂøóÔºà‰ºòÂÖàÈÖçÁΩÆÔºâ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

# Load environment variables from .env file
try:
    from dotenv import load_dotenv
    load_dotenv()  # Ëá™Âä®Âä†ËΩΩÂΩìÂâçÁõÆÂΩï‰∏ãÁöÑ.envÊñá‰ª∂
    logger.info("‚úÖ Â∑≤Âä†ËΩΩ.envÁéØÂ¢ÉÂèòÈáèÊñá‰ª∂")
except ImportError:
    logger.warning("‚ö†Ô∏è python-dotenvÊú™ÂÆâË£ÖÔºåÂ∞ÜÁõ¥Êé•‰ªéÁ≥ªÁªüÁéØÂ¢ÉÂèòÈáèËØªÂèñÈÖçÁΩÆ")
except Exception as e:
    logger.warning(f"‚ö†Ô∏è Âä†ËΩΩ.envÊñá‰ª∂Êó∂Âá∫Áé∞ÈóÆÈ¢ò: {e}")

def get_api_key() -> str:
    """Ëé∑ÂèñOpenRouter APIÂØÜÈí•"""
    api_key = os.environ.get("OPENROUTER_API_KEY")
    if not api_key:
        # Ê£ÄÊü•ÊòØÂê¶ÊòØÊµãËØïÊ®°Âºè
        test_mode = os.environ.get("TEST_MODE", "false").lower() == "true"
        if test_mode:
            logger.warning("‚ö†Ô∏è ÊµãËØïÊ®°ÂºèÔºö‰ΩøÁî®Ê®°ÊãüAPIÂØÜÈí•")
            return "test-api-key-for-testing"
        
        logger.error("‚ùå Êú™ÊâæÂà∞OPENROUTER_API_KEY")
        logger.error("ËØ∑Âú®.envÊñá‰ª∂‰∏≠ËÆæÁΩÆ: OPENROUTER_API_KEY=your-api-key-here")
        logger.error("ÊàñËÆæÁΩÆÁ≥ªÁªüÁéØÂ¢ÉÂèòÈáè: export OPENROUTER_API_KEY='your-api-key-here'")
        logger.error("ÊàñËÆæÁΩÆTEST_MODE=trueËøõÂÖ•ÊµãËØïÊ®°Âºè")
        raise RuntimeError("Áº∫Â∞ëÂøÖÈúÄÁöÑAPIÂØÜÈí•ÈÖçÁΩÆ")
    return api_key

# Á°Æ‰øùËæìÂá∫ÁõÆÂΩïÂ≠òÂú®
OUTPUT_DIR = "generated_docs"
if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)

class DocumentExtractor:
    """ÊñáÊ°£ÂÜÖÂÆπÊèêÂèñÂô®"""
    
    def __init__(self):
        logger.info("üìÑ ÊñáÊ°£ÊèêÂèñÂô®ÂàùÂßãÂåñÂÆåÊàê")
    
    def extract_from_file_path(self, file_path: str) -> str:
        """‰ªéÊñá‰ª∂Ë∑ØÂæÑÊèêÂèñÂÜÖÂÆπ"""
        if not os.path.exists(file_path):
            raise ProcessingError(
                f"ÂéüÂßãÊñáÊ°£‰∏çÂ≠òÂú®: {file_path}",
                "FILE_NOT_FOUND",
                404
            )
        return self._extract_content(file_path)
    
    def _extract_content(self, file_path: str) -> str:
        """ÊèêÂèñÊñáÊ°£ÂÜÖÂÆπÁöÑÊ†∏ÂøÉÊñπÊ≥ï"""
        logger.info(f"üìÑ ÂºÄÂßãÊèêÂèñÊñáÊ°£ÂÜÖÂÆπ: {Path(file_path).name}")
        
        content = ""
        
        try:
            file_ext = Path(file_path).suffix.lower()
            
            if file_ext == '.docx':
                doc = DocxDocument(file_path)
                content = "\n".join([para.text for para in doc.paragraphs])
                
                # ÊèêÂèñË°®Ê†ºÂÜÖÂÆπ
                for table in doc.tables:
                    for row in table.rows:
                        row_text = " | ".join([cell.text.strip() for cell in row.cells])
                        if row_text.strip():
                            content += f"\nË°®Ê†ºË°å: {row_text}"
            
            elif file_ext == '.pdf':
                doc = fitz.open(file_path)
                for page in doc:
                    content += page.get_text()
                doc.close()
            
            elif file_ext in ['.txt', '.md']:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
            
            else:
                raise ProcessingError(
                    f"‰∏çÊîØÊåÅÁöÑÊñá‰ª∂Ê†ºÂºè: {file_ext}",
                    "UNSUPPORTED_FORMAT",
                    422
                )
            
            if not content.strip():
                raise ProcessingError(
                    "ÊñáÊ°£ÂÜÖÂÆπ‰∏∫Á©∫",
                    "EMPTY_DOCUMENT",
                    422
                )
            
            logger.info(f"‚úÖ ÊàêÂäüÊèêÂèñÂÜÖÂÆπÔºåÈïøÂ∫¶: {len(content)} Â≠óÁ¨¶")
            return content.strip()
            
        except ProcessingError:
            raise
        except Exception as e:
            logger.error(f"‚ùå ÊèêÂèñÊñáÊ°£ÂÜÖÂÆπÂ§±Ë¥•: {e}")
            raise ProcessingError(
                f"ÊñáÊ°£ÂÜÖÂÆπÊèêÂèñÂ§±Ë¥•: {str(e)}",
                "EXTRACTION_ERROR",
                500
            )

class ContentMerger:
    """ÂÜÖÂÆπÊô∫ËÉΩÂêàÂπ∂Âô®"""
    
    def __init__(self, api_key: str):
        """ÂàùÂßãÂåñAIÂÆ¢Êà∑Á´Ø"""
        self.client = OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=api_key,
        )
        self.model = "google/gemini-2.5-pro-preview"
        logger.info("üß† ÂÜÖÂÆπÂêàÂπ∂Âô®ÂàùÂßãÂåñÂÆåÊàê")
    
    def merge_content(self, template_json: Dict[str, str], original_content: str) -> Dict[str, str]:
        """‰ΩøÁî®AIÊô∫ËÉΩÂêàÂπ∂Ê®°ÊùøJSONÂíåÂéüÂßãÂÜÖÂÆπ"""
        logger.info("üß† ÂºÄÂßãAIÊô∫ËÉΩÂêàÂπ∂...")
        
        # Ê£ÄÊü•ÊòØÂê¶ÊòØÊµãËØïÊ®°Âºè
        test_mode = os.environ.get("TEST_MODE", "false").lower() == "true"
        if test_mode or self.client.api_key == "test-api-key-for-testing":
            logger.warning("‚ö†Ô∏è ÊµãËØïÊ®°ÂºèÔºö‰ΩøÁî®Ê®°ÊãüAIÂêàÂπ∂")
            return self._mock_merge_content(template_json, original_content)
        
        prompt = f"""
‰Ω†ÊòØ‰∏Ä‰∏™‰∏ì‰∏öÁöÑÊñáÊ°£Â§ÑÁêÜAIÂä©Êâã„ÄÇËØ∑Ê†πÊçÆÊèê‰æõÁöÑÊ®°ÊùøJSONÁªìÊûÑÂíåÂéüÂßãÊñáÊ°£ÂÜÖÂÆπÔºåËøõË°åÊô∫ËÉΩÂêàÂπ∂„ÄÇ

Ê®°ÊùøJSONÁªìÊûÑÔºö
{json.dumps(template_json, ensure_ascii=False, indent=2)}

ÂéüÂßãÊñáÊ°£ÂÜÖÂÆπÔºö
{original_content}

‰ªªÂä°Ë¶ÅÊ±ÇÔºö
1. ÂàÜÊûêÊ®°ÊùøJSON‰∏≠ÊØè‰∏™Á´†ËäÇÁöÑË¶ÅÊ±Ç
2. ‰ªéÂéüÂßãÊñáÊ°£ÂÜÖÂÆπ‰∏≠ÊèêÂèñÁõ∏ÂÖ≥‰ø°ÊÅØ
3. ËøõË°åËØ≠‰πâÂåπÈÖçÂíåÂÜÖÂÆπÊï¥Âêà
4. ÁîüÊàêÁ¨¶ÂêàÊ®°ÊùøÁªìÊûÑÁöÑÂÜÖÂÆπ

ËæìÂá∫Ë¶ÅÊ±ÇÔºö
- ÂøÖÈ°ªËøîÂõûJSONÊ†ºÂºè
- ÈîÆÂêç‰∏éÊ®°ÊùøJSONÂÆåÂÖ®‰∏ÄËá¥
- ÂÄº‰∏∫Ê†πÊçÆÂéüÂßãÂÜÖÂÆπÊô∫ËÉΩÁîüÊàêÁöÑÂÖ∑‰ΩìÂÜÖÂÆπ
- Â¶ÇÊûúÂéüÂßãÂÜÖÂÆπ‰∏≠Ê≤°ÊúâÁõ∏ÂÖ≥‰ø°ÊÅØÔºåËØ∑Âü∫‰∫éÂêàÁêÜÊé®ÊµãÁîüÊàêÂÜÖÂÆπ
- ÊØè‰∏™Á´†ËäÇÂÜÖÂÆπÂ∫îËØ•ÂÆåÊï¥„ÄÅ‰∏ì‰∏ö„ÄÅÁ¨¶ÂêàÂÆûÈôÖ

ËØ∑Áõ¥Êé•ËøîÂõûJSONÊ†ºÂºèÁöÑÁªìÊûúÔºå‰∏çË¶ÅÂåÖÂê´‰ªª‰ΩïËß£ÈáäÊñáÂ≠ó„ÄÇ
"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,
            )
            
            if not response or not response.choices or not response.choices[0].message.content:
                raise ProcessingError(
                    "AIÂìçÂ∫îÊó†ÊïàÊàñ‰∏∫Á©∫",
                    "AI_NO_RESPONSE",
                    500
                )
            
            # ÊèêÂèñJSONÂÜÖÂÆπ
            response_content = response.choices[0].message.content.strip()
            json_str = self._extract_json_from_response(response_content)
            
            try:
                merged_content = json.loads(json_str)
            except json.JSONDecodeError as e:
                logger.error(f"‚ùå JSONËß£ÊûêÂ§±Ë¥•: {e}")
                logger.error(f"AIÂìçÂ∫îÂÜÖÂÆπ: {response_content}")
                raise ProcessingError(
                    f"AIËøîÂõûÁöÑÂÜÖÂÆπ‰∏çÊòØÊúâÊïàÁöÑJSONÊ†ºÂºè: {str(e)}",
                    "AI_INVALID_JSON",
                    422
                )
            
            # È™åËØÅÂêàÂπ∂ÁªìÊûú
            if not isinstance(merged_content, dict):
                raise ProcessingError(
                    "AIËøîÂõûÁöÑÂÜÖÂÆπ‰∏çÊòØÂ≠óÂÖ∏Ê†ºÂºè",
                    "AI_INVALID_FORMAT",
                    422
                )
            
            logger.info(f"‚úÖ AIÂêàÂπ∂ÊàêÂäüÔºåÁîüÊàê {len(merged_content)} ‰∏™Á´†ËäÇ")
            for key, value in merged_content.items():
                preview = str(value)[:100] + "..." if len(str(value)) > 100 else str(value)
                logger.info(f"   üìù {key}: {preview}")
            
            return merged_content
            
        except ProcessingError:
            raise
        except Exception as e:
            logger.error(f"‚ùå AIÂêàÂπ∂Â§±Ë¥•: {e}")
            raise ProcessingError(
                f"AIÂêàÂπ∂ËøáÁ®ã‰∏≠ÂèëÁîüÈîôËØØ: {str(e)}",
                "AI_MERGE_ERROR",
                500
            )
    
    def _mock_merge_content(self, template_json: Dict[str, str], original_content: str) -> Dict[str, str]:
        """Ê®°ÊãüAIÂêàÂπ∂ÔºàÊµãËØïÊ®°ÂºèÔºâ"""
        logger.info("üß™ Ê®°ÊãüAIÂêàÂπ∂Ê®°Âºè")
        
        merged_content = {}
        content_lines = original_content.split('\n')
        content_preview = ' '.join(content_lines[:5])[:200]
        
        for key, description in template_json.items():
            # Âü∫‰∫éÂéüÂßãÂÜÖÂÆπÂíåÊ®°ÊùøÊèèËø∞ÁîüÊàêÁÆÄÂçïÁöÑÂêàÂπ∂ÂÜÖÂÆπ
            merged_content[key] = f"""Ê†πÊçÆÂéüÂßãÊñáÊ°£ÂÜÖÂÆπÁîüÊàêÁöÑ{key}Á´†ËäÇÔºö

{description}

Âü∫‰∫éÂéüÂßãÊñáÊ°£ÁöÑÁõ∏ÂÖ≥‰ø°ÊÅØÔºö
{content_preview}

Êú¨Á´†ËäÇÂÜÖÂÆπÂ∑≤Ê†πÊçÆÊ®°ÊùøË¶ÅÊ±ÇËøõË°åÊô∫ËÉΩÊï¥ÂêàÔºåÁ°Æ‰øùÁ¨¶ÂêàÂ∑•Á®ãÊñáÊ°£ÁöÑÊ†áÂáÜÊ†ºÂºèÂíåË¶ÅÊ±Ç„ÄÇÂÖ∑‰ΩìÂÜÖÂÆπÂåÖÊã¨È°πÁõÆÁöÑÂü∫Êú¨ÊÉÖÂÜµ„ÄÅÊäÄÊúØË¶ÅÊ±Ç„ÄÅÂÆûÊñΩÊñπÊ°àÁ≠âÂÖ≥ÈîÆ‰ø°ÊÅØ„ÄÇ

Ê≥®ÔºöÊ≠§ÂÜÖÂÆπÁî±ÊµãËØïÊ®°ÂºèÁîüÊàêÔºåÂÆûÈôÖÂ∫îÁî®‰∏≠Â∞Ü‰ΩøÁî®ÁúüÂÆûAIËøõË°åÊô∫ËÉΩÂêàÂπ∂„ÄÇ"""
        
        logger.info(f"‚úÖ Ê®°ÊãüÂêàÂπ∂ÂÆåÊàêÔºåÁîüÊàê {len(merged_content)} ‰∏™Á´†ËäÇ")
        return merged_content
    
    def _extract_json_from_response(self, response_content: str) -> str:
        """‰ªéAIÂìçÂ∫î‰∏≠ÊèêÂèñJSONÂÜÖÂÆπ"""
        # Â∞ùËØïÊèêÂèñJSON
        if "```json" in response_content:
            start = response_content.find("```json") + 7
            end = response_content.find("```", start)
            if end != -1:
                return response_content[start:end].strip()
            else:
                return response_content[response_content.find("```json") + 7:].strip()
        elif response_content.startswith("{") and response_content.endswith("}"):
            return response_content
        else:
            # Êü•ÊâæJSONÂØπË±°
            start_idx = response_content.find("{")
            if start_idx != -1:
                brace_count = 0
                for i, char in enumerate(response_content[start_idx:], start_idx):
                    if char == "{":
                        brace_count += 1
                    elif char == "}":
                        brace_count -= 1
                        if brace_count == 0:
                            return response_content[start_idx:i+1]
                brace_count = 0
                for i, char in enumerate(response_content[start_idx:], start_idx):
                    if char == "{":
                        brace_count += 1
                    elif char == "}":
                        brace_count -= 1
                        if brace_count == 0:
                            return response_content[start_idx:i+1]
            return response_content

class DocumentGenerator:
    """ÊñáÊ°£ÁîüÊàêÂô®"""
    
    def __init__(self):
        logger.info("üìÑ ÊñáÊ°£ÁîüÊàêÂô®ÂàùÂßãÂåñÂÆåÊàê")
    
    def generate_docx(self, merged_content: Dict[str, str], output_path: str) -> Dict[str, Any]:
        """ÁîüÊàêÊúÄÁªàÁöÑdocxÊñáÊ°£"""
        logger.info("üìÑ ÂºÄÂßãÁîüÊàêdocxÊñáÊ°£...")
        
        try:
            doc = Document()
            
            # ËÆæÁΩÆÊñáÊ°£Ê†áÈ¢ò
            title = doc.add_heading('AIÊô∫ËÉΩÂêàÂπ∂ÊñáÊ°£', 0)
            title.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
            
            # Ê∑ªÂä†ÁîüÊàêÊó∂Èó¥
            timestamp = datetime.now().strftime('%YÂπ¥%mÊúà%dÊó• %H:%M:%S')
            time_para = doc.add_paragraph(f'ÁîüÊàêÊó∂Èó¥: {timestamp}')
            time_para.alignment = WD_PARAGRAPH_ALIGNMENT.RIGHT
            
            doc.add_page_break()
            
            # Ê∑ªÂä†ÁõÆÂΩïÊ†áÈ¢ò
            doc.add_heading('ÁõÆÂΩï', level=1)
            
            # ÁîüÊàêÁõÆÂΩï
            for i, section_title in enumerate(merged_content.keys(), 1):
                toc_para = doc.add_paragraph(f"{i}. {section_title}")
                toc_para.style = 'List Number'
            
            doc.add_page_break()
            
            # Ê∑ªÂä†Ê≠£ÊñáÂÜÖÂÆπ
            for i, (section_title, section_content) in enumerate(merged_content.items(), 1):
                # Ê∑ªÂä†Á´†ËäÇÊ†áÈ¢ò
                heading = doc.add_heading(f"{i}. {section_title}", level=1)
                
                # Ê∑ªÂä†Á´†ËäÇÂÜÖÂÆπ
                if isinstance(section_content, str):
                    # Â§ÑÁêÜÂ§öÊÆµËêΩÂÜÖÂÆπ
                    paragraphs = section_content.split('\n\n')
                    for para_text in paragraphs:
                        if para_text.strip():
                            para = doc.add_paragraph(para_text.strip())
                            para.style = 'Normal'
                elif isinstance(section_content, list):
                    # Â§ÑÁêÜÂàóË°®ÂÜÖÂÆπ
                    for item in section_content:
                        para = doc.add_paragraph(str(item))
                        para.style = 'List Bullet'
                else:
                    # ÂÖ∂‰ªñÁ±ªÂûãËΩ¨‰∏∫Â≠óÁ¨¶‰∏≤
                    para = doc.add_paragraph(str(section_content))
                    para.style = 'Normal'
                
                # Ê∑ªÂä†Á´†ËäÇÈó¥Ë∑ù
                doc.add_paragraph()
            
            # Ê∑ªÂä†È°µËÑö
            footer_section = doc.sections[0]
            footer = footer_section.footer
            footer_para = footer.paragraphs[0]
            footer_para.text = "Êú¨ÊñáÊ°£Áî±AIÊô∫ËÉΩÂêàÂπ∂Á≥ªÁªüËá™Âä®ÁîüÊàê"
            footer_para.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
            
            # ‰øùÂ≠òÊñáÊ°£
            doc.save(output_path)
            logger.info(f"‚úÖ ÊàêÂäüÁîüÊàêdocxÊñáÊ°£: {output_path}")
            
            # È™åËØÅÊñáÊ°£Âπ∂ËøîÂõûÁªüËÆ°‰ø°ÊÅØ
            validation_info = self._validate_docx(output_path)
            
            return {
                "sections_count": len(merged_content),
                "file_size": os.path.getsize(output_path),
                "validation": validation_info
            }
            
        except ProcessingError:
            raise
        except Exception as e:
            logger.error(f"‚ùå ÁîüÊàêdocxÊñáÊ°£Â§±Ë¥•: {e}")
            raise ProcessingError(
                f"ÊñáÊ°£ÁîüÊàêÂ§±Ë¥•: {str(e)}",
                "DOCUMENT_GENERATION_ERROR",
                500
            )
    
    def _validate_docx(self, file_path: str) -> Dict[str, Any]:
        """È™åËØÅÁîüÊàêÁöÑdocxÊñáÊ°£"""
        try:
            # Â∞ùËØïÊâìÂºÄÊñáÊ°£ËøõË°åÈ™åËØÅ
            doc = Document(file_path)
            paragraph_count = len(doc.paragraphs)
            table_count = len(doc.tables)
            
            if paragraph_count == 0:
                raise ProcessingError(
                    "ÁîüÊàêÁöÑÊñáÊ°£‰∏∫Á©∫",
                    "EMPTY_GENERATED_DOCUMENT",
                    500
                )
            
            validation_info = {
                "paragraph_count": paragraph_count,
                "table_count": table_count,
                "is_valid": True
            }
            
            logger.info(f"‚úÖ ÊñáÊ°£È™åËØÅÈÄöËøáÔºåÂåÖÂê´ {paragraph_count} ‰∏™ÊÆµËêΩ")
            return validation_info
            
        except ProcessingError:
            raise
        except Exception as e:
            logger.error(f"‚ùå ÊñáÊ°£È™åËØÅÂ§±Ë¥•: {e}")
            raise ProcessingError(
                f"ÁîüÊàêÁöÑÊñáÊ°£Ê†ºÂºèÊúâËØØ: {str(e)}",
                "DOCUMENT_VALIDATION_ERROR",
                500
            )

class TemplateInserter:
    """Ê®°ÊùøÊèíÂÖ•Ë∞ÉÂ∫¶Âô® - ÂçèË∞ÉÂêÑ‰∏™ÁªÑ‰ª∂"""
    
    def __init__(self, api_key: str):
        """ÂàùÂßãÂåñÂêÑ‰∏™ÁªÑ‰ª∂"""
        self.extractor = DocumentExtractor()
        self.merger = ContentMerger(api_key)
        self.generator = DocumentGenerator()
        logger.info("ü§ñ Ê®°ÊùøÊèíÂÖ•Ë∞ÉÂ∫¶Âô®ÂàùÂßãÂåñÂÆåÊàê")
    
    def process_from_file_path(self, template_json: Dict[str, str], original_file_path: str) -> Dict[str, Any]:
        """‰ªéÊñá‰ª∂Ë∑ØÂæÑÂ§ÑÁêÜÊ®°ÊùøÊèíÂÖ•ÔºàÂêëÂêéÂÖºÂÆπÔºâ"""
        logger.info("üöÄ ÂºÄÂßãÊñá‰ª∂Ë∑ØÂæÑÊ®°ÂºèÁöÑÊ®°ÊùøÊèíÂÖ•Â§ÑÁêÜ...")
        
        # 1. ÊèêÂèñÂéüÂßãÊñáÊ°£ÂÜÖÂÆπ
        original_content = self.extractor.extract_from_file_path(original_file_path)
        
        # 2. AIÊô∫ËÉΩÂêàÂπ∂
        merged_content = self.merger.merge_content(template_json, original_content)
        
        # 3. ÁîüÊàêËæìÂá∫Êñá‰ª∂Ë∑ØÂæÑ
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_filename = f"merged_document_{timestamp}.docx"
        output_path = os.path.join(OUTPUT_DIR, output_filename)
        
        # 4. ÁîüÊàêdocxÊñáÊ°£
        generation_info = self.generator.generate_docx(merged_content, output_path)
        
        logger.info(f"‚úÖ Ê®°ÊùøÊèíÂÖ•Â§ÑÁêÜÂÆåÊàê: {output_path}")
        return {
            "final_doc_path": output_path,
            "generation_info": generation_info,
            "content_summary": {key: len(str(value)) for key, value in merged_content.items()}
        }

def run_template_insertion(template_json_input: Union[str, Dict[str, str]], original_file_path: str) -> str:
    """
    AI tool to merge a document with a JSON template to generate a new docx file.
    
    It uses an AI model to intelligently merge content from the original document 
    (e.g., .docx, .pdf, .txt) into the structure defined by the JSON template.

    Args:
        template_json_input: A dictionary or file path for the template JSON.
        original_file_path: The path to the original document file.

    Returns:
        The file path of the generated .docx document.
    """
    logger.info("üöÄ Starting template insertion process...")
    
    try:
        # Load template json if a path is provided
        if isinstance(template_json_input, str):
            if not os.path.exists(template_json_input):
                raise FileNotFoundError(f"Template JSON file not found: {template_json_input}")
            with open(template_json_input, 'r', encoding='utf-8') as f:
                template_json = json.load(f)
        else:
            template_json = template_json_input

        # Get API key and initialize inserter
        api_key = get_api_key()
        inserter = TemplateInserter(api_key)

        # Process and get result
        result = inserter.process_from_file_path(template_json, original_file_path)
        
        final_doc_path = result["final_doc_path"]
        logger.info(f"‚úÖ Template insertion process completed successfully. Document saved at: {final_doc_path}")
        
        return final_doc_path

    except (ProcessingError, FileNotFoundError) as e:
        logger.error(f"‚ùå Processing failed: {e}")
        raise
    except Exception as e:
        logger.error(f"‚ùå An unexpected error occurred during template insertion: {e}")
        logger.error(traceback.format_exc())
        raise ProcessingError(f"An unexpected error occurred: {str(e)}", "UNEXPECTED_ERROR", 500)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="AI-powered document generation from a template.",
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument("template_json_path", help="Path to the template JSON file.")
    parser.add_argument("original_file_path", help="Path to the original document file (.docx, .pdf, .txt).")

    print("=" * 70)
    print("ü§ñ AI Document Template Inserter")
    print("=" * 70)
    
    # Ê£ÄÊü•APIÂØÜÈí•ÈÖçÁΩÆ
    try:
        api_key = get_api_key()
        logger.info(f"‚úÖ API key found (length: {len(api_key)}).")
    except Exception as e:
        logger.error(f"‚ùå Critical Error: {e}")
        print("\nConfiguration Help:")
        print("1. Create a file named .env in the same directory.")
        print("2. Add this line to it: OPENROUTER_API_KEY=your-api-key-here")
        print("\nAlternatively, set a system environment variable.")
        exit(1)

    args = parser.parse_args()

    print(f"\n‚ñ∂Ô∏è Starting process with:")
    print(f"   Template: {args.template_json_path}")
    print(f"   Original Document: {args.original_file_path}")
    print("-" * 70)

    try:
        output_file = run_template_insertion(
            template_json_input=args.template_json_path,
            original_file_path=args.original_file_path
        )
        print(f"\n‚úÖ Success! Generated document saved at:")
        print(f"   -> {output_file}")

    except FileNotFoundError as e:
        print(f"\n‚ùå Error: File not found.")
        print(f"   Details: {e}")
    except ProcessingError as e:
        print(f"\n‚ùå Error during processing: {e.error_code}")
        print(f"   Details: {e.message}")
    except Exception as e:
        print(f"\n‚ùå An unexpected error occurred.")
        traceback.print_exc()
    
    print("=" * 70)
    print("‚úÖ Process finished.")
    print("=" * 70) 