#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸»ç¨‹åºï¼šAIæ–‡æ¡£ç”Ÿæˆå™¨
æ”¯æŒä¸‰é˜¶æ®µæµç¨‹ï¼šDOCè½¬æ¢ â†’ æ¨¡æ¿åˆ†æ â†’ JSONè¾“å…¥ â†’ æ–‡æ¡£ç”Ÿæˆ
"""

import os
import json
import logging
import subprocess
from datetime import datetime
from typing import Dict, Any, List, Optional
from docx import Document
from docx.shared import Inches, Pt
from openai import OpenAI
import base64
import mimetypes
import fitz  # PyMuPDF
from docx import Document as DocxDocument
import re

# Load environment variables from .env file if it exists
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    # python-dotenv not installed, skip .env file loading
    pass

# Import prompts
from prompt_utils import get_fill_data_prompt, get_multimodal_extraction_prompt

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

# Define a directory for uploads and temporary files
UPLOADS_DIR = "uploads"
if not os.path.exists(UPLOADS_DIR):
    os.makedirs(UPLOADS_DIR)

class AIDocGenerator:
    """AIæ–‡æ¡£ç”Ÿæˆå™¨ - æ”¯æŒDOCè½¬æ¢"""
    
    def __init__(self, api_key: str):
        """åˆå§‹åŒ–OpenRouterå®¢æˆ·ç«¯"""
        self.client = OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=api_key,
        )
        self.model = "google/gemini-2.5-pro-preview"
        self.placeholder_originals = {}  # Store original text of placeholders
        logger.info("ğŸ¤– AIç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _extract_json_from_response(self, response_content: str) -> str:
        """
        Extract JSON string from AI response content.
        Handles various formats like markdown code blocks, plain JSON, etc.
        """
        if not response_content or not response_content.strip():
            raise ValueError("AI response content is empty")
        
        content = response_content.strip()
        
        # Try to extract from markdown code block
        if "```json" in content:
            try:
                start = content.find("```json") + 7
                end = content.find("```", start)
                if end != -1:
                    json_str = content[start:end].strip()
                    if json_str:
                        return json_str
            except Exception:
                pass
        
        # Try to extract from single backticks
        if content.startswith("`") and content.endswith("`"):
            json_str = content.strip("`").strip()
            if json_str:
                return json_str
        
        # Try to find JSON object boundaries
        start_idx = content.find("{")
        if start_idx != -1:
            # Find the matching closing brace
            brace_count = 0
            for i, char in enumerate(content[start_idx:], start_idx):
                if char == "{":
                    brace_count += 1
                elif char == "}":
                    brace_count -= 1
                    if brace_count == 0:
                        json_str = content[start_idx:i+1]
                        # Validate it's proper JSON
                        try:
                            json.loads(json_str)
                            return json_str
                        except json.JSONDecodeError:
                            continue
        
        # If all else fails, try the content as-is
        try:
            json.loads(content)
            return content
        except json.JSONDecodeError:
            raise ValueError(f"Could not extract valid JSON from AI response: {content[:200]}...")

    def convert_doc_to_docx(self, doc_path: str) -> str:
        """
        ä½¿ç”¨LibreOfficeå°†.docæ–‡ä»¶è½¬æ¢ä¸º.docxæ–‡ä»¶
        
        Args:
            doc_path: .docæ–‡ä»¶è·¯å¾„
            
        Returns:
            è½¬æ¢åçš„.docxæ–‡ä»¶è·¯å¾„
        """
        logger.info("ğŸ”„ å¼€å§‹DOCåˆ°DOCXè½¬æ¢...")
        
        if not os.path.exists(doc_path):
            logger.error(f"âŒ DOCæ–‡ä»¶ä¸å­˜åœ¨: {doc_path}")
            raise FileNotFoundError(f"DOCæ–‡ä»¶ä¸å­˜åœ¨: {doc_path}")
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        docx_path = doc_path.replace('.doc', '_converted.docx')
        
        try:
            # æ£€æŸ¥LibreOfficeæ˜¯å¦å¯ç”¨
            logger.info("ğŸ” æ£€æŸ¥LibreOfficeå¯ç”¨æ€§...")
            
            # å°è¯•å¤šä¸ªå¯èƒ½çš„LibreOfficeè·¯å¾„
            libreoffice_paths = [
                '/Applications/LibreOffice.app/Contents/MacOS/soffice',  # macOS
                'libreoffice',  # Linux/Windows PATH
                'soffice',  # å¤‡ç”¨å‘½ä»¤
            ]
            
            libreoffice_cmd = None
            for path in libreoffice_paths:
                try:
                    result = subprocess.run([path, '--version'], 
                                          capture_output=True, 
                                          text=True, 
                                          timeout=10)
                    if result.returncode == 0:
                        libreoffice_cmd = path
                        logger.info(f"âœ… æ‰¾åˆ°LibreOffice: {path}")
                        break
                except (FileNotFoundError, subprocess.TimeoutExpired):
                    continue
            
            if not libreoffice_cmd:
                logger.error("âŒ æœªæ‰¾åˆ°LibreOfficeï¼Œè¯·ç¡®ä¿å·²å®‰è£…LibreOffice")
                raise RuntimeError("LibreOfficeæœªå®‰è£…æˆ–ä¸å¯ç”¨")
            
            # æ‰§è¡Œè½¬æ¢
            logger.info(f"ğŸ“„ æ­£åœ¨è½¬æ¢: {doc_path} -> {docx_path}")
            
            # åˆ é™¤å·²å­˜åœ¨çš„è¾“å‡ºæ–‡ä»¶
            if os.path.exists(docx_path):
                os.remove(docx_path)
                logger.info("ğŸ—‘ï¸ åˆ é™¤å·²å­˜åœ¨çš„è½¬æ¢æ–‡ä»¶")
            
            # LibreOfficeè½¬æ¢å‘½ä»¤
            cmd = [
                libreoffice_cmd,
                '--headless',
                '--convert-to', 'docx',
                '--outdir', os.path.dirname(doc_path),
                doc_path
            ]
            
            logger.info(f"ğŸ”§ æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
            
            result = subprocess.run(cmd, 
                                  capture_output=True, 
                                  text=True, 
                                  timeout=30)
            
            if result.returncode != 0:
                logger.error(f"âŒ LibreOfficeè½¬æ¢å¤±è´¥: {result.stderr}")
                raise RuntimeError(f"LibreOfficeè½¬æ¢å¤±è´¥: {result.stderr}")
            
            # æ£€æŸ¥è½¬æ¢åçš„æ–‡ä»¶
            expected_docx = doc_path.replace('.doc', '.docx')
            if os.path.exists(expected_docx):
                # é‡å‘½åä¸ºæˆ‘ä»¬æœŸæœ›çš„æ–‡ä»¶å
                if expected_docx != docx_path:
                    os.rename(expected_docx, docx_path)
                
                logger.info(f"âœ… è½¬æ¢æˆåŠŸ: {docx_path}")
                return docx_path
            else:
                logger.error(f"âŒ è½¬æ¢åçš„æ–‡ä»¶æœªæ‰¾åˆ°: {expected_docx}")
                raise RuntimeError("è½¬æ¢åçš„æ–‡ä»¶æœªæ‰¾åˆ°")
                
        except subprocess.TimeoutExpired:
            logger.error("âŒ LibreOfficeè½¬æ¢è¶…æ—¶")
            raise RuntimeError("LibreOfficeè½¬æ¢è¶…æ—¶")
        except Exception as e:
            logger.error(f"âŒ è½¬æ¢è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            raise
    
    def _replace_text_in_element(self, element, old_text, new_text):
        """Helper to replace text in a paragraph or cell, preserving style."""
        # This is a simplified replacement. For complex formatting (multiple runs),
        # a more sophisticated run-by-run replacement would be needed.
        # For this use case, we assume clearing and adding a new run is acceptable.
        if isinstance(element, type(doc.paragraphs[0])): # Paragraph
             # To preserve overall paragraph style, we only change the text
             for run in element.runs:
                 if old_text in run.text:
                     run.text = run.text.replace(old_text, new_text)
        else: # Cell
             element.text = element.text.replace(old_text, new_text)

    def stage1_analyze_template(self, template_path: str) -> Dict[str, str]:
        """
        é˜¶æ®µ1ï¼šç¡®å®šæ€§åœ°åˆ†æWordæ¨¡æ¿ï¼Œæå–å¸¦æœ‰ä½ç½®ä¿¡æ¯çš„ç»“æ„ã€‚
        
        Args:
            template_path: .docxæ¨¡æ¿æ–‡ä»¶è·¯å¾„

        Returns:
            ä¸€ä¸ªå­—å…¸ï¼Œå…¶ä¸­é”®æ˜¯å•å…ƒæ ¼çš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œå€¼æ˜¯å•å…ƒæ ¼çš„æ–‡æœ¬å†…å®¹ã€‚
        """
        logger.info("ğŸ” é˜¶æ®µ1ï¼šå¼€å§‹ç¡®å®šæ€§æ¨¡æ¿ç»“æ„åˆ†æ...")
        
        try:
            doc = Document(template_path)
            template_structure = {}
            
            logger.info(f"ğŸ“„ æ­£åœ¨è¯»å–æ¨¡æ¿æ–‡ä»¶: {template_path}")
            
            # æå–è¡¨æ ¼ç»“æ„
            for i, table in enumerate(doc.tables):
                for j, row in enumerate(table.rows):
                    for k, cell in enumerate(row.cells):
                        cell_key = f"table_{i}_row_{j}_col_{k}"
                        template_structure[cell_key] = cell.text.strip()
            
            # æå–æ®µè½ç»“æ„ï¼ˆä¸åšç‰¹æ®Šå¤„ç†ï¼Œä¿æŒåŸå§‹å†…å®¹ï¼‰
            for i, para in enumerate(doc.paragraphs):
                para_key = f"paragraph_{i}"
                template_structure[para_key] = para.text.strip()
            
            logger.info(f"âœ… æˆåŠŸæå– {len(template_structure)} ä¸ªç»“æ„å…ƒç´ ã€‚")
            
            # Log a snippet of the extracted structure for verification
            structure_snippet = json.dumps(dict(list(template_structure.items())[:5]), ensure_ascii=False, indent=2)
            logger.info(f"  ç»“æ„å®ä¾‹:\n{structure_snippet}")

            return template_structure
            
        except Exception as e:
            logger.error(f"âŒ é˜¶æ®µ1é”™è¯¯: {e}")
            raise

    def _preprocess_template_and_extract_placeholders(self, doc_path: str, output_path: str) -> List[str]:
        """
        æ‰©å±•å ä½ç¬¦é¢„å¤„ç†ï¼Œä»¥åŒ…å«é€šç”¨çš„ä¸‹åˆ’çº¿å­—æ®µï¼Œå¹¶ä¼˜åŒ–æ›¿æ¢é€»è¾‘
        """
        logger.info("ğŸ› ï¸  é˜¶æ®µ 0: å¼€å§‹æ‰©å±•å ä½ç¬¦é¢„å¤„ç†...")
        
        self.placeholder_originals = {} # Reset for each new template analysis
        doc = Document(doc_path)
        placeholders = set()
        blank_counter = 0 # Counter for generic underscore placeholders
        
        def process_text_and_extract_keys(text: str) -> (str, List[str]):
            nonlocal blank_counter
            found_keys = []

            def repl_func(match):
                nonlocal blank_counter
                # Pattern for 'è‡´...': underscore_str in group(1), hint in group(2)
                if match.group(1) is not None:
                    if "ï¼ˆç­¾å­—ï¼‰" in match.group(0) or "(ç­¾å­—)" in match.group(0):
                        return match.group(0)
                    
                    underscore_str = match.group(1)
                    hint = match.group(2)
                    placeholder_key = f"inline_{hint}"
                    found_keys.append(placeholder_key)
                    self.placeholder_originals[placeholder_key] = underscore_str
                    replacement = f"è‡´{{{placeholder_key}}}ï¼ˆ{hint}ï¼‰"
                    logger.info(f"   - å‘ç°å†…è”æ¨¡å¼: '{match.group(0)}' -> '{replacement}'")
                    return replacement

                # Pattern for 'label:': label in group(3)
                elif match.group(3) is not None:
                    # The regex now prevents matching 'ï¼ˆç­¾å­—ï¼‰:'
                    label = match.group(3).strip()
                    placeholder_key = f"label_{label}"
                    found_keys.append(placeholder_key)
                    replacement = f"{label}ï¼š{{{placeholder_key}}}"
                    logger.info(f"   - å‘ç°æ ‡ç­¾æ¨¡å¼: '{match.group(0)}' -> '{replacement}'")
                    return replacement

                # Pattern for general underscores: underscore_str in group(4)
                elif match.group(4) is not None:
                    underscore_str = match.group(4)
                    placeholder_key = f"blank_{blank_counter}"
                    found_keys.append(placeholder_key)
                    self.placeholder_originals[placeholder_key] = underscore_str
                    replacement = f"{{{placeholder_key}}}"
                    logger.info(f"   - å‘ç°é€šç”¨ä¸‹åˆ’çº¿æ¨¡å¼: '{underscore_str}' -> '{replacement}'")
                    blank_counter += 1
                    return replacement
                
                return match.group(0)

            # Regex updated to handle spaced underscores and avoid capturing signature labels
            pattern = re.compile(
                r"è‡´\s*(__{3,})\s*ï¼ˆ([^ï¼‰]+)ï¼‰"              # G1: underscore, G2: hint
                r"|([^ï¼š\nï¼ˆ(]+?)ï¼š\s*$"                    # G3: label, avoids '(...):'
                r"|((?:_{4,}[\s\xa0]*)+)"               # G4: general underscore blocks
            )

            processed_text = pattern.sub(repl_func, text)
            
            return processed_text, found_keys
        
        # --- Process all paragraphs ---
        for para in doc.paragraphs:
            original_text = para.text
            if not original_text.strip():
                continue

            new_text, keys = process_text_and_extract_keys(original_text)
            if new_text != original_text:
                placeholders.update(keys)
                # To preserve formatting, we clear runs and add a new one
                para.clear()
                para.add_run(new_text)
                logger.info(f"   ğŸ“ æ®µè½æ›´æ–°: '{original_text.strip()}' -> '{new_text.strip()}'")

        # --- Process all tables ---
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    original_text = cell.text
                    if not original_text.strip():
                        continue
                        
                    new_text, keys = process_text_and_extract_keys(original_text)
                    if new_text != original_text:
                        placeholders.update(keys)
                        # Reverted to cell.text for simplicity and correctness.
                        # This replaces the content of the first paragraph in the cell.
                        cell.text = new_text
                        logger.info(f"   ğŸ“‹ è¡¨æ ¼æ›´æ–°: '{original_text.strip()}' -> '{new_text.strip()}'")
        
        doc.save(output_path)
        logger.info(f"âœ… æ‰©å±•é¢„å¤„ç†å®Œæˆ. æ‰¾åˆ° {len(placeholders)} ä¸ªå ä½ç¬¦. æ–°æ¨¡æ¿: {output_path}")
        return list(placeholders)

    def stage2_5_ai_generate_fill_data(self, template_structure: Dict[str, str], placeholders: List[str], input_data: Dict[str, Any]) -> Dict[str, str]:
        """
        é˜¶æ®µ2.5ï¼šæ··åˆæ¨¡å¼ - ä½¿ç”¨AIåŒæ—¶å¤„ç†æ¨¡æ¿ç»“æ„åŒ¹é…å’Œå ä½ç¬¦åŒ¹é…
        """
        logger.info("ğŸ§  é˜¶æ®µ 2.5ï¼šå¼€å§‹æ··åˆæ¨¡å¼AIå­—æ®µæ˜ å°„...")
        
        try:
            # æ„å»ºæ··åˆæç¤º
            prompt = get_fill_data_prompt(
                json.dumps(template_structure, ensure_ascii=False, indent=2),
                json.dumps(placeholders, ensure_ascii=False, indent=2),
                json.dumps(input_data, ensure_ascii=False, indent=2)
            )
            
            logger.info("ğŸ§  æ­£åœ¨è°ƒç”¨AIè¿›è¡Œæ··åˆæ¨¡å¼æ˜ å°„...")
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,
            )
            
            if not response or not response.choices or not response.choices[0].message.content:
                raise ValueError("AIå“åº”æ— æ•ˆæˆ–ä¸ºç©º")

            json_string = self._extract_json_from_response(response.choices[0].message.content)
            fill_data = json.loads(json_string)
            
            logger.info(f"âœ… AIæˆåŠŸç”Ÿæˆ {len(fill_data)} ä¸ªå­—æ®µçš„æ˜ å°„:")
            for key, value in fill_data.items():
                preview = str(value)[:70] + "..." if len(str(value)) > 70 else str(value)
                logger.info(f"   ğŸ”— {key} -> '{preview}'")
            
            return fill_data
            
        except Exception as e:
            logger.error(f"âŒ é˜¶æ®µ 2.5 é”™è¯¯: {e}", exc_info=True)
            return {}

    def stage3_fill_template(self, template_path: str, output_path: str, fill_data: Dict[str, str]):
        """
        é˜¶æ®µ3ï¼šæ··åˆå¡«å…… - æ”¯æŒå›¾ç‰‡é™„ä»¶å’Œå ä½ç¬¦
        """
        logger.info("ğŸ“ é˜¶æ®µ 3ï¼šå¼€å§‹æ··åˆæ¨¡å¼æ¨¡æ¿å¡«å……...")
        
        doc = Document(template_path)
        filled_count = 0
        
        # 1. å‡†å¤‡é™„ä»¶ä¿¡æ¯
        attachments_map = fill_data.pop('attachments_map', {})
        attachment_ref_map = {}
        ordered_attachments = []
        if attachments_map and isinstance(attachments_map, dict):
            logger.info(f"ğŸ–¼ï¸  æ‰¾åˆ° {len(attachments_map)} ä¸ªå›¾ç‰‡é™„ä»¶å¾…å¤„ç†ã€‚")
            ordered_attachments = list(attachments_map.items())
            for i, (key, _) in enumerate(ordered_attachments):
                attachment_ref_map[key.strip()] = i + 1
        else:
            attachments_map = {}

        # 2. åˆ†ç¦»æ–‡æœ¬å¡«å……æ•°æ®
        placeholder_data = {k: v for k, v in fill_data.items() if k.startswith(('label_', 'inline_', 'blank_'))}
        structure_data = {k: v for k, v in fill_data.items() if k.startswith(('table_', 'paragraph_'))}
        
        # 3. æ›¿æ¢æ‰€æœ‰æ–‡æœ¬å ä½ç¬¦ï¼ˆåŒ…æ‹¬å›¾ç‰‡å¼•ç”¨ï¼‰
        image_placeholder_pattern = re.compile(r'\{\{image:([^}]+)\}\}')
        text_placeholder_pattern = re.compile(r'\{(label_[^}]+|inline_[^}]+|blank_[^}]+)\}')

        def process_element_text(element):
            nonlocal filled_count
            if '{' not in element.text:
                return

            original_text = element.text
            new_text = ""
            last_end = 0

            # åˆ›å»ºä¸€ä¸ªç»„åˆçš„æ­£åˆ™è¡¨è¾¾å¼æ¥æŸ¥æ‰¾æ‰€æœ‰ç±»å‹çš„å ä½ç¬¦
            combined_pattern = re.compile(f"({image_placeholder_pattern.pattern}|{text_placeholder_pattern.pattern})")
            
            for match in combined_pattern.finditer(original_text):
                new_text += original_text[last_end:match.start()]
                last_end = match.end()
                
                image_key_match = image_placeholder_pattern.match(match.group(0))
                text_key_match = text_placeholder_pattern.match(match.group(0))

                if image_key_match:
                    key = image_key_match.group(1).strip()
                    if key in attachment_ref_map:
                        number = attachment_ref_map[key]
                        replacement = f"ï¼ˆè¯¦è§é™„ä»¶{number}ï¼‰"
                        new_text += replacement
                        logger.info(f"   ğŸ–¼ï¸  å›¾ç‰‡å¼•ç”¨æ›¿æ¢: '{match.group(0)}' -> '{replacement}'")
                    else:
                        logger.warning(f"   âš ï¸  æ‰¾åˆ°å›¾ç‰‡å ä½ç¬¦ {match.group(0)} ä½†æ— åŒ¹é…å›¾ç‰‡ï¼Œå·²ç§»é™¤ã€‚")
                
                elif text_key_match:
                    placeholder_key = text_key_match.group(1)
                    placeholder = f"{{{placeholder_key}}}"

                    if placeholder_key in placeholder_data:
                        value = str(placeholder_data[placeholder_key])
                        new_text += value
                        logger.info(f"   âœï¸  å ä½ç¬¦å¡«å……: {placeholder} -> {value[:50]}...")
                        filled_count += 1
                    else: # æœªåŒ¹é…çš„æ–‡æœ¬å ä½ç¬¦
                        if placeholder_key.startswith('label_'):
                            logger.info(f"   ğŸ”˜  ç§»é™¤æœªåŒ¹é…æ ‡ç­¾å ä½ç¬¦: {placeholder}")
                            # The replacement is empty string, so we add nothing
                        elif placeholder_key.startswith(('inline_', 'blank_')):
                            original_underscore = self.placeholder_originals.get(placeholder_key, '____')
                            new_text += original_underscore
                            logger.info(f"   ğŸ”˜  æ¢å¤æœªåŒ¹é…å ä½ç¬¦: {placeholder} -> '{original_underscore}'")

            new_text += original_text[last_end:]
            
            if new_text != original_text:
                element.text = new_text

        # éå†æ®µè½å’Œè¡¨æ ¼è¿›è¡Œç»Ÿä¸€æ›¿æ¢
        for para in doc.paragraphs:
            process_element_text(para)
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    process_element_text(cell)

        # 4. å¡«å……åŸå§‹ç»“æ„
        for i, table in enumerate(doc.tables):
            for j, row in enumerate(table.rows):
                for k, cell in enumerate(row.cells):
                    cell_key = f"table_{i}_row_{j}_col_{k}"
                    if cell_key in structure_data:
                        cell.text = str(structure_data[cell_key])
                        logger.info(f"   âœï¸  ç»“æ„å¡«å……(è¡¨æ ¼): {cell_key} -> {str(structure_data[cell_key])[:50]}...")
                        filled_count += 1

        for i, para in enumerate(doc.paragraphs):
            para_key = f"paragraph_{i}"
            if para_key in structure_data:
                # åªæœ‰åœ¨æ®µè½ä¸­æ²¡æœ‰å ä½ç¬¦çš„æƒ…å†µä¸‹æ‰è¿›è¡Œç»“æ„å¡«å……
                if not combined_pattern.search(para.text):
                    para.text = str(structure_data[para_key])
                    logger.info(f"   âœï¸  ç»“æ„å¡«å……(æ®µè½): {para_key} -> {str(structure_data[para_key])[:50]}...")
                    filled_count += 1

        # 5. å°†å›¾ç‰‡ä½œä¸ºé™„ä»¶é™„åŠ åˆ°æ–‡æ¡£æœ«å°¾
        if ordered_attachments:
            logger.info("ğŸ“ å¼€å§‹åœ¨æ–‡æ¡£æœ«å°¾é™„åŠ å›¾ç‰‡...")
            try:
                doc.add_page_break()
                doc.add_heading('é™„ä»¶åˆ—è¡¨', level=1)
                
                for i, (key, image_path) in enumerate(ordered_attachments):
                    attachment_counter = i + 1
                    if not image_path or not isinstance(image_path, str) or not os.path.exists(image_path):
                        logger.warning(f"âš ï¸ å›¾ç‰‡è·¯å¾„ä¸å­˜åœ¨æˆ–æ— æ•ˆï¼Œè·³è¿‡é™„ä»¶ '{key}': {image_path}")
                        continue
                    
                    try:
                        heading_text = f"é™„ä»¶ {attachment_counter}: {key}"
                        doc.add_heading(heading_text, level=2)
                        doc.add_picture(image_path, width=Inches(6.0))
                        doc.add_paragraph()
                        logger.info(f"   âœ… æˆåŠŸé™„åŠ å›¾ç‰‡: {heading_text} ({image_path})")
                    except Exception as pic_e:
                        logger.error(f"âŒ é™„åŠ å›¾ç‰‡ '{key}' ({image_path}) æ—¶å‡ºé”™: {pic_e}")
            except Exception as e:
                logger.error(f"âŒ å¤„ç†é™„ä»¶æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")
        
        doc.save(output_path)
        logger.info(f"âœ… æ··åˆæ¨¡å¼å¡«å……å®Œæˆï¼Œå…±å¡«å…… {filled_count} ä¸ªå­—æ®µ: {output_path}")

    def run_generation(
        self, 
        doc_template_path: str, 
        output_path: str, 
        attachment_paths: Optional[List[str]] = None,
        direct_json_data: Optional[Dict[str, Any]] = None
    ):
        """
        è¿è¡Œæ··åˆæ¨¡å¼çš„æ–‡æ¡£ç”Ÿæˆæµç¨‹
        """
        logger.info("ğŸš€ Starting hybrid document generation process...")
        
        try:
            # Stage 0: Convert .doc to .docx if necessary
            if doc_template_path.lower().endswith('.doc'):
                logger.info(f"ğŸ“„ Detected .doc template. Attempting conversion for: {doc_template_path}")
                original_docx_path = self.convert_doc_to_docx(doc_template_path)
            else:
                original_docx_path = doc_template_path

            # Stage 0.5: é¢„å¤„ç†æ¨¡æ¿ï¼Œåªå¤„ç†ç‰¹å®šçš„ä¸¤ç§æƒ…å†µ
            processed_template_path = original_docx_path.replace(".docx", "_processed.docx")
            placeholders = self._preprocess_template_and_extract_placeholders(
                doc_path=original_docx_path,
                output_path=processed_template_path
            )
            
            # Stage 1: åˆ†æå¤„ç†åçš„æ¨¡æ¿ç»“æ„
            template_structure = self.stage1_analyze_template(processed_template_path)

            # Stage 2: Get input data (either direct or from AI extraction)
            input_data = {}
            if direct_json_data:
                logger.info("ğŸ“„ Using user-provided JSON data directly.")
                input_data = direct_json_data
            elif attachment_paths:
                logger.info("ğŸ§  No direct JSON provided, starting AI extraction from attachments.")
                input_data = self.stage2_1_ai_extract_data_from_sources(
                    attachment_paths=attachment_paths
                )
            else:
                raise ValueError("Generation failed: You must provide either direct JSON data or attachment files.")

            # Stage 2.5: æ··åˆæ¨¡å¼AIæ˜ å°„
            fill_data = self.stage2_5_ai_generate_fill_data(
                template_structure=template_structure,
                placeholders=placeholders,
                input_data=input_data
            )
            
            # Stage 3: æ··åˆæ¨¡å¼å¡«å……
            self.stage3_fill_template(
                template_path=processed_template_path,
                output_path=output_path,
                fill_data=fill_data
            )
            
            logger.info(f"âœ… Hybrid document generation complete: {output_path}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Document generation failed: {e}", exc_info=True)
            return False

    def stage2_1_ai_extract_data_from_sources(self, attachment_paths: List[str]) -> Dict[str, Any]:
        """
        Stage 2.1: Use multimodal AI to extract data from various documents and images.
        """
        logger.info("ğŸ§  Stage 2.1: Kicking off multimodal AI data extraction...")
        
        try:
            # This is a sample schema. In a real app, this might come from the template
            # or a user configuration. For now, we'll use a schema based on sample_input.json
            fields_to_extract = json.dumps({
                "serial_number": "ç¤ºä¾‹: GZ-FH-2025-001",
                "project_name": "ç¤ºä¾‹: å†å²å»ºç­‘ä¿®å¤é¡¹ç›®",
                "review_date": "ç¤ºä¾‹: 2025-01-25",
                "original_condition_review": "å»ºç­‘ç‰©åŸå§‹çŠ¶æ€çš„æè¿°ã€‚",
                "damage_assessment_review": "å‘ç°çš„ä»»ä½•æŸä¼¤çš„è¯¦ç»†è¯„ä¼°ã€‚",
                "repair_plan_review": "æ‹Ÿå®šçš„ä¿®å¤è®¡åˆ’ã€‚",
                "project_lead": "é¡¹ç›®è´Ÿè´£äººå§“åã€‚",
                "reviewer": "å®¡æ ¸äººå‘˜å§“åã€‚",
                "attachments_map": "ä¸€ä¸ªJSONå¯¹è±¡ï¼Œå°†æè¿°æ€§é”®åæ˜ å°„åˆ°ç›¸åº”çš„å›¾åƒæ–‡ä»¶è·¯å¾„ã€‚é”®ååº”ä¸ºç®€çŸ­çš„è‹±æ–‡/æ‹¼éŸ³ï¼ˆä¾‹å¦‚ 'gongDiZhaoPian1', 'sunHuaiTu'ï¼‰ã€‚ç¤ºä¾‹: {'shiGongTu': 'path/to/drawing.png', 'xianChangZhaoPian': 'path/to/site_photo.jpg'}"
            }, indent=2, ensure_ascii=False)

            prompt = get_multimodal_extraction_prompt(fields_to_extract)

            # Build the message with text and images
            content_parts = [{"type": "text", "text": prompt}]
            
            # --- Unified File Processing Loop ---
            image_paths_for_prompt = []
            temp_text_files = []

            for file_path in attachment_paths:
                file_name = os.path.basename(file_path)
                logger.info(f"ğŸ“„ Processing attachment: {file_name}")

                try:
                    if file_path.endswith(('.txt', '.md', '.json')):
                        with open(file_path, 'r', encoding='utf-8') as f:
                            file_content = f.read()
                        text_part = f"\n\n--- Content from {file_name} ---\n{file_content}\n--- End of Content ---"
                        content_parts[0]["text"] += text_part

                    elif file_path.endswith('.docx'):
                        doc = DocxDocument(file_path)
                        full_text = "\n".join([p.text for p in doc.paragraphs])
                        text_part = f"\n\n--- Content from {file_name} ---\n{full_text}\n--- End of Content ---"
                        content_parts[0]["text"] += text_part

                    elif file_path.endswith('.pdf'):
                        doc = fitz.open(file_path)
                        full_text = ""
                        for page_num, page in enumerate(doc):
                            full_text += page.get_text()
                            # Extract images from PDF
                            img_list = page.get_images(full=True)
                            for img_index, img in enumerate(img_list):
                                xref = img[0]
                                base_image = doc.extract_image(xref)
                                image_bytes = base_image["image"]
                                image_ext = base_image["ext"]
                                
                                # Save image to a temporary file
                                temp_image_filename = f"pdf_{os.path.splitext(file_name)[0]}_p{page_num+1}_img{img_index}.{image_ext}"
                                temp_image_path = os.path.join(UPLOADS_DIR, temp_image_filename)
                                with open(temp_image_path, "wb") as f:
                                    f.write(image_bytes)
                                
                                image_paths_for_prompt.append(temp_image_path)
                                logger.info(f"ğŸ–¼ï¸  Extracted image from PDF: {temp_image_path}")
                        
                        text_part = f"\n\n--- Content from {file_name} ---\n{full_text}\n--- End of Content ---"
                        content_parts[0]["text"] += text_part
                        doc.close()

                    else: # Assumes it's an image if not a text-based file
                        mime_type, _ = mimetypes.guess_type(file_path)
                        if mime_type and mime_type.startswith('image/'):
                            image_paths_for_prompt.append(file_path)
                        else:
                            logger.warning(f"âš ï¸ Unsupported file type, skipping: {file_name}")

                except Exception as e:
                    logger.error(f"âŒ Error processing file {file_path}: {e}", exc_info=True)


            # Add all collected images to the prompt
            for image_path in image_paths_for_prompt:
                try:
                    mime_type, _ = mimetypes.guess_type(image_path)
                    with open(image_path, "rb") as image_file:
                        base64_image = base64.b64encode(image_file.read()).decode('utf-8')
                    
                    image_url = f"data:{mime_type};base64,{base64_image}"
                    
                    # Add a reference in the text part with Chinese description
                    content_parts[0]["text"] += f"\n\n--- é™„åŠ å›¾åƒ (æ–‡ä»¶è·¯å¾„: {image_path}) ---"
                    
                    content_parts.append({
                        "type": "image_url",
                        "image_url": {"url": image_url}
                    })
                    logger.info(f"ğŸ–¼ï¸  Added image {image_path} to AI prompt.")
                except Exception as e:
                    logger.warning(f"âš ï¸ Could not process image file {image_path}: {e}")

            logger.info("ğŸ§  Calling multimodal AI to extract structured data... (This may take a moment)")
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": content_parts}],
                temperature=0.1
            )
            
            # Clean up extracted text files
            for path in temp_text_files:
                try:
                    os.remove(path)
                except OSError as e:
                    logger.error(f"Error removing temp text file {path}: {e}")
            
            # Extract and parse the JSON from the AI's response
            if response.choices[0].message.content:
                json_string = self._extract_json_from_response(response.choices[0].message.content)
                extracted_data = json.loads(json_string)
                
                logger.info(f"âœ… AI successfully extracted data. Keys: {list(extracted_data.keys())}")
                return extracted_data
            else:
                raise ValueError("AI returned an empty response.")
                
        except Exception as e:
            logger.error(f"âŒ Stage 2.1 Error: {e}", exc_info=True)
            raise

    def run_complete_workflow(self, doc_template_path: str, json_input_path: str, output_path: str):
        """
        è¿è¡Œå®Œæ•´çš„3é˜¶æ®µå·¥ä½œæµï¼ˆä»æ¨¡æ¿å’ŒJSONæ–‡ä»¶ï¼‰
        This is now a wrapper around the more flexible run_generation method.
        """
        logger.info("ğŸš€ å¼€å§‹å®Œæ•´çš„AIæ–‡æ¡£ç”Ÿæˆæµç¨‹")
        logger.info("=" * 60)
        
        # é˜¶æ®µ 1ï¼šä»JSONæ–‡ä»¶åŠ è½½æ•°æ®
        logger.info("ğŸ“‚ é˜¶æ®µ 1ï¼šå¼€å§‹åŠ è½½JSONæ•°æ®...")
        input_data = {}
        try:
            if not os.path.exists(json_input_path):
                logger.error(f"âŒ JSONæ–‡ä»¶ä¸å­˜åœ¨: {json_input_path}")
                raise FileNotFoundError(f"JSONæ–‡ä»¶ä¸å­˜åœ¨: {json_input_path}")
            
            with open(json_input_path, 'r', encoding='utf-8') as f:
                input_data = json.load(f)
            
            logger.info(f"âœ… æˆåŠŸåŠ è½½ {len(input_data)} ä¸ªæ•°æ®å­—æ®µã€‚")
        except Exception as e:
            logger.error(f"âŒ åŠ è½½JSONæ•°æ®æ—¶å‡ºé”™: {e}", exc_info=True)
            return False

        # é˜¶æ®µ 2 & 3: è°ƒç”¨ç»Ÿä¸€çš„ç”Ÿæˆæµç¨‹
        return self.run_generation(
            doc_template_path=doc_template_path,
            output_path=output_path,
            direct_json_data=input_data
        )


def main():
    """ä¸»å‡½æ•° - å®Œæ•´ç³»ç»Ÿå¥å£®æ€§æµ‹è¯•"""
    print("ğŸš€ AIæ–‡æ¡£ç”Ÿæˆå™¨ - å®Œæ•´ç³»ç»Ÿå¥å£®æ€§æµ‹è¯•")
    print("=" * 60)
    
    # --- é…ç½® ---
    API_KEY = os.environ.get("OPENROUTER_API_KEY")
    
    if not API_KEY:
        logger.error("âŒ é”™è¯¯: æœªæ‰¾åˆ° OPENROUTER_API_KEY ç¯å¢ƒå˜é‡")
        logger.error("è¯·è®¾ç½®ç¯å¢ƒå˜é‡:")
        logger.error("  macOS/Linux: export OPENROUTER_API_KEY='your-api-key-here'")
        logger.error("  Windows: set OPENROUTER_API_KEY=your-api-key-here")
        logger.error("æˆ–è€…åˆ›å»º .env æ–‡ä»¶å¹¶æ·»åŠ : OPENROUTER_API_KEY=your-api-key-here")
        return

    # åˆ›å»ºæµ‹è¯•ç¯å¢ƒ
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    test_dir = f"test_outputs_{timestamp}"
    os.makedirs(test_dir, exist_ok=True)
    
    try:
        logger.info("ğŸ§ª å¼€å§‹åˆ›å»ºæµ‹è¯•ç¯å¢ƒ...")
        
        # 1. åˆ›å»ºå¸¦å›¾ç‰‡å ä½ç¬¦çš„æµ‹è¯•æ¨¡æ¿
        test_template_path = create_test_template_with_images(test_dir)
        
        # 2. åˆ›å»ºæµ‹è¯•å›¾ç‰‡æ–‡ä»¶
        test_images = create_test_images(test_dir)
        
        # 3. åˆ›å»ºæµ‹è¯•JSONæ•°æ®ï¼ˆåŒ…å«å›¾ç‰‡æ˜ å°„ï¼‰
        test_json_path = create_test_json_with_images(test_dir, test_images)
        
        # 4. åˆå§‹åŒ–AIç”Ÿæˆå™¨
        generator = AIDocGenerator(API_KEY)
        
        # 5. è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶
        test_results = run_comprehensive_tests(generator, test_template_path, test_json_path, test_images, test_dir)
        
        # 6. ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        generate_test_report(test_results, test_dir)
        
        print(f"\nâœ… å®Œæ•´ç³»ç»Ÿæµ‹è¯•å®Œæˆï¼")
        print(f"ğŸ“ æµ‹è¯•ç»“æœä¿å­˜åœ¨: {test_dir}/")
        print(f"ğŸ“Š æµ‹è¯•æŠ¥å‘Š: {test_dir}/test_report.md")
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
        print(f"\nâŒ æµ‹è¯•å¤±è´¥ï¼é”™è¯¯è¯¦æƒ…è¯·æŸ¥çœ‹æ—¥å¿—ã€‚")

def create_test_template_with_images(test_dir: str) -> str:
    """åˆ›å»ºåŒ…å«å›¾ç‰‡å ä½ç¬¦çš„æµ‹è¯•æ¨¡æ¿"""
    logger.info("ğŸ“„ åˆ›å»ºæµ‹è¯•æ¨¡æ¿...")
    
    from docx import Document
    from docx.shared import Inches
    
    doc = Document()
    
    # æ·»åŠ æ ‡é¢˜
    doc.add_heading('AIæ–‡æ¡£ç”Ÿæˆå™¨æµ‹è¯•æŠ¥å‘Š', 0)
    
    # æ·»åŠ åŸºæœ¬ä¿¡æ¯è¡¨æ ¼
    table = doc.add_table(rows=5, cols=2)
    table.style = 'Table Grid'
    
    # å¡«å……è¡¨æ ¼å†…å®¹
    cells_data = [
        ('é¡¹ç›®åç§°ï¼š', ''),
        ('é¡¹ç›®è´Ÿè´£äººï¼š', ''),
        ('å®¡æ ¸æ—¥æœŸï¼š', ''),
        ('è‡´____ï¼ˆç›‘ç†å•ä½ï¼‰', ''),
        ('å®¡æ ¸äººï¼ˆç­¾å­—ï¼‰ï¼š', '')
    ]
    
    for i, (label, value) in enumerate(cells_data):
        table.cell(i, 0).text = label
        table.cell(i, 1).text = value
    
    # æ·»åŠ æ­£æ–‡å†…å®¹ï¼ˆåŒ…å«å›¾ç‰‡å ä½ç¬¦ï¼‰
    doc.add_heading('ä¸€ã€é¡¹ç›®æ¦‚è¿°', level=1)
    doc.add_paragraph('æœ¬é¡¹ç›®ä¸ºAIæ–‡æ¡£ç”Ÿæˆå™¨çš„å®Œæ•´åŠŸèƒ½æµ‹è¯•ã€‚')
    
    doc.add_heading('äºŒã€æ–½å·¥å›¾çº¸', level=1)
    doc.add_paragraph('è¯¦ç»†çš„æ–½å·¥å›¾çº¸è¯·å‚è€ƒï¼š{{image:shiGongTu}}')
    
    doc.add_heading('ä¸‰ã€ç°åœºç…§ç‰‡', level=1)
    doc.add_paragraph('ç°åœºå®é™…æƒ…å†µç…§ç‰‡è¯¦è§ï¼š{{image:xianChangZhaoPian}}')
    
    doc.add_heading('å››ã€æŸåè¯„ä¼°', level=1)
    doc.add_paragraph('å»ºç­‘ç‰©æŸåæƒ…å†µçš„è¯¦ç»†å›¾åƒè¯·æŸ¥çœ‹ï¼š{{image:sunHuaiTu}}')
    
    doc.add_heading('äº”ã€è®¾è®¡æ–¹æ¡ˆ', level=1)
    doc.add_paragraph('æœ€ç»ˆçš„è®¾è®¡æ–¹æ¡ˆå›¾çº¸è¯·å‚è€ƒï¼š{{image:sheJiTu}}')
    
    # ä¿å­˜æ¨¡æ¿
    template_path = os.path.join(test_dir, 'test_template_with_images.docx')
    doc.save(template_path)
    
    logger.info(f"âœ… æµ‹è¯•æ¨¡æ¿åˆ›å»ºå®Œæˆ: {template_path}")
    return template_path

def create_test_images(test_dir: str) -> Dict[str, str]:
    """åˆ›å»ºæµ‹è¯•å›¾ç‰‡æ–‡ä»¶"""
    logger.info("ğŸ–¼ï¸  åˆ›å»ºæµ‹è¯•å›¾ç‰‡...")
    
    try:
        from PIL import Image, ImageDraw, ImageFont
    except ImportError:
        logger.warning("âš ï¸ PILæœªå®‰è£…ï¼Œåˆ›å»ºç®€å•çš„æµ‹è¯•å›¾ç‰‡æ–‡ä»¶")
        # åˆ›å»ºç®€å•çš„æµ‹è¯•æ–‡ä»¶ä½œä¸ºå ä½ç¬¦
        test_images = {}
        image_names = ['shiGongTu', 'xianChangZhaoPian', 'sunHuaiTu', 'sheJiTu']
        
        for name in image_names:
            file_path = os.path.join(test_dir, f'{name}.txt')
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(f"æµ‹è¯•å›¾ç‰‡å ä½ç¬¦: {name}\nè¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿçš„å›¾ç‰‡æ–‡ä»¶ã€‚")
            test_images[name] = file_path
        
        return test_images
    
    # åˆ›å»ºæµ‹è¯•å›¾ç‰‡
    test_images = {}
    image_configs = [
        ('shiGongTu', 'æ–½å·¥å›¾çº¸', (800, 600), 'lightblue'),
        ('xianChangZhaoPian', 'ç°åœºç…§ç‰‡', (640, 480), 'lightgreen'),
        ('sunHuaiTu', 'æŸåå›¾ç‰‡', (600, 400), 'lightcoral'),
        ('sheJiTu', 'è®¾è®¡å›¾çº¸', (800, 600), 'lightyellow')
    ]
    
    for name, title, size, color in image_configs:
        img = Image.new('RGB', size, color)
        draw = ImageDraw.Draw(img)
        
        # æ·»åŠ æ–‡å­—
        try:
            # å°è¯•ä½¿ç”¨ç³»ç»Ÿå­—ä½“
            font = ImageFont.truetype("arial.ttf", 36)
        except:
            font = ImageFont.load_default()
        
        text = f"{title}\næµ‹è¯•å›¾ç‰‡"
        bbox = draw.textbbox((0, 0), text, font=font)
        text_width = bbox[2] - bbox[0]
        text_height = bbox[3] - bbox[1]
        
        x = (size[0] - text_width) // 2
        y = (size[1] - text_height) // 2
        
        draw.text((x, y), text, fill='black', font=font)
        
        # ä¿å­˜å›¾ç‰‡
        file_path = os.path.join(test_dir, f'{name}.png')
        img.save(file_path)
        test_images[name] = file_path
        
        logger.info(f"   âœ… åˆ›å»ºæµ‹è¯•å›¾ç‰‡: {file_path}")
    
    return test_images

def create_test_json_with_images(test_dir: str, test_images: Dict[str, str]) -> str:
    """åˆ›å»ºåŒ…å«å›¾ç‰‡æ˜ å°„çš„æµ‹è¯•JSONæ•°æ®"""
    logger.info("ğŸ“ åˆ›å»ºæµ‹è¯•JSONæ•°æ®...")
    
    test_data = {
        "serial_number": "TEST-2025-001",
        "project_name": "AIæ–‡æ¡£ç”Ÿæˆå™¨å®Œæ•´åŠŸèƒ½æµ‹è¯•é¡¹ç›®",
        "review_date": "2025-01-20",
        "original_condition_review": "ç³»ç»ŸåŸå§‹çŠ¶æ€è‰¯å¥½ï¼Œæ‰€æœ‰åŠŸèƒ½æ¨¡å—æ­£å¸¸è¿è¡Œã€‚",
        "damage_assessment_review": "ç»è¿‡å…¨é¢æµ‹è¯•ï¼Œå‘ç°ç³»ç»Ÿåœ¨å›¾ç‰‡å¤„ç†æ–¹é¢éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚",
        "repair_plan_review": "åˆ¶å®šäº†å®Œå–„çš„å›¾ç‰‡é™„ä»¶å¤„ç†æ–¹æ¡ˆï¼Œç¡®ä¿æ–‡æ¡£ç”Ÿæˆçš„å®Œæ•´æ€§ã€‚",
        "project_lead": "AIæµ‹è¯•å·¥ç¨‹å¸ˆ",
        "reviewer": "ç³»ç»Ÿæ¶æ„å¸ˆ",
        "supervision_company": "AIæŠ€æœ¯ç›‘ç†æœ‰é™å…¬å¸",
        "attachments_map": test_images
    }
    
    json_path = os.path.join(test_dir, 'test_data_with_images.json')
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(test_data, f, ensure_ascii=False, indent=2)
    
    logger.info(f"âœ… æµ‹è¯•JSONæ•°æ®åˆ›å»ºå®Œæˆ: {json_path}")
    return json_path

def run_comprehensive_tests(generator, template_path: str, json_path: str, test_images: Dict[str, str], test_dir: str) -> Dict[str, Any]:
    """è¿è¡Œç»¼åˆæµ‹è¯•å¥—ä»¶"""
    logger.info("ğŸ§ª å¼€å§‹è¿è¡Œç»¼åˆæµ‹è¯•å¥—ä»¶...")
    
    test_results = {
        "tests_run": 0,
        "tests_passed": 0,
        "tests_failed": 0,
        "details": []
    }
    
    # æµ‹è¯•1: åŸºæœ¬æ–‡æ¡£ç”Ÿæˆ
    test_results["tests_run"] += 1
    try:
        output_path = os.path.join(test_dir, 'test_output_basic.docx')
        with open(json_path, 'r', encoding='utf-8') as f:
            test_data = json.load(f)
        
        success = generator.run_generation(
            doc_template_path=template_path,
            output_path=output_path,
            direct_json_data=test_data
        )
        
        if success and os.path.exists(output_path):
            test_results["tests_passed"] += 1
            test_results["details"].append({
                "test": "åŸºæœ¬æ–‡æ¡£ç”Ÿæˆ",
                "status": "âœ… é€šè¿‡",
                "output": output_path
            })
        else:
            test_results["tests_failed"] += 1
            test_results["details"].append({
                "test": "åŸºæœ¬æ–‡æ¡£ç”Ÿæˆ", 
                "status": "âŒ å¤±è´¥",
                "error": "æ–‡æ¡£ç”Ÿæˆå¤±è´¥æˆ–è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨"
            })
    except Exception as e:
        test_results["tests_failed"] += 1
        test_results["details"].append({
            "test": "åŸºæœ¬æ–‡æ¡£ç”Ÿæˆ",
            "status": "âŒ å¼‚å¸¸",
            "error": str(e)
        })
    
    # æµ‹è¯•2: å›¾ç‰‡å ä½ç¬¦å¤„ç†
    test_results["tests_run"] += 1
    try:
        # éªŒè¯ç”Ÿæˆçš„æ–‡æ¡£æ˜¯å¦åŒ…å«æ­£ç¡®çš„å›¾ç‰‡å¼•ç”¨
        output_path = os.path.join(test_dir, 'test_output_basic.docx')
        if os.path.exists(output_path):
            from docx import Document
            doc = Document(output_path)
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«"è¯¦è§é™„ä»¶"æ–‡æœ¬
            found_references = False
            for para in doc.paragraphs:
                if "è¯¦è§é™„ä»¶" in para.text:
                    found_references = True
                    break
            
            if found_references:
                test_results["tests_passed"] += 1
                test_results["details"].append({
                    "test": "å›¾ç‰‡å ä½ç¬¦å¤„ç†",
                    "status": "âœ… é€šè¿‡",
                    "note": "æˆåŠŸæ‰¾åˆ°å›¾ç‰‡å¼•ç”¨æ–‡æœ¬"
                })
            else:
                test_results["tests_failed"] += 1
                test_results["details"].append({
                    "test": "å›¾ç‰‡å ä½ç¬¦å¤„ç†",
                    "status": "âŒ å¤±è´¥", 
                    "error": "æœªæ‰¾åˆ°å›¾ç‰‡å¼•ç”¨æ–‡æœ¬"
                })
        else:
            test_results["tests_failed"] += 1
            test_results["details"].append({
                "test": "å›¾ç‰‡å ä½ç¬¦å¤„ç†",
                "status": "âŒ å¤±è´¥",
                "error": "è¾“å‡ºæ–‡æ¡£ä¸å­˜åœ¨"
            })
    except Exception as e:
        test_results["tests_failed"] += 1
        test_results["details"].append({
            "test": "å›¾ç‰‡å ä½ç¬¦å¤„ç†",
            "status": "âŒ å¼‚å¸¸",
            "error": str(e)
        })
    
    # æµ‹è¯•3: é”™è¯¯å¤„ç†å’Œå¥å£®æ€§
    test_results["tests_run"] += 1
    try:
        # æµ‹è¯•ä¸å­˜åœ¨çš„å›¾ç‰‡è·¯å¾„
        invalid_data = test_data.copy()
        invalid_data["attachments_map"] = {
            "nonexistent": "/path/to/nonexistent/image.png"
        }
        
        output_path = os.path.join(test_dir, 'test_output_robustness.docx')
        success = generator.run_generation(
            doc_template_path=template_path,
            output_path=output_path,
            direct_json_data=invalid_data
        )
        
        if success:
            test_results["tests_passed"] += 1
            test_results["details"].append({
                "test": "é”™è¯¯å¤„ç†å’Œå¥å£®æ€§",
                "status": "âœ… é€šè¿‡",
                "note": "ç³»ç»Ÿæ­£ç¡®å¤„ç†äº†æ— æ•ˆå›¾ç‰‡è·¯å¾„"
            })
        else:
            test_results["tests_failed"] += 1
            test_results["details"].append({
                "test": "é”™è¯¯å¤„ç†å’Œå¥å£®æ€§",
                "status": "âŒ å¤±è´¥",
                "error": "ç³»ç»Ÿæœªèƒ½æ­£ç¡®å¤„ç†é”™è¯¯æƒ…å†µ"
            })
    except Exception as e:
        test_results["tests_failed"] += 1
        test_results["details"].append({
            "test": "é”™è¯¯å¤„ç†å’Œå¥å£®æ€§",
            "status": "âŒ å¼‚å¸¸",
            "error": str(e)
        })
    
    return test_results

def generate_test_report(test_results: Dict[str, Any], test_dir: str):
    """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
    logger.info("ğŸ“Š ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š...")
    
    report_path = os.path.join(test_dir, 'test_report.md')
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("# AIæ–‡æ¡£ç”Ÿæˆå™¨ - å®Œæ•´ç³»ç»Ÿæµ‹è¯•æŠ¥å‘Š\n\n")
        f.write(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        f.write("## æµ‹è¯•æ¦‚è¦\n\n")
        f.write(f"- æ€»æµ‹è¯•æ•°: {test_results['tests_run']}\n")
        f.write(f"- é€šè¿‡æµ‹è¯•: {test_results['tests_passed']}\n")
        f.write(f"- å¤±è´¥æµ‹è¯•: {test_results['tests_failed']}\n")
        f.write(f"- æˆåŠŸç‡: {test_results['tests_passed']/test_results['tests_run']*100:.1f}%\n\n")
        
        f.write("## è¯¦ç»†æµ‹è¯•ç»“æœ\n\n")
        for detail in test_results['details']:
            f.write(f"### {detail['test']}\n\n")
            f.write(f"**çŠ¶æ€**: {detail['status']}\n\n")
            if 'output' in detail:
                f.write(f"**è¾“å‡ºæ–‡ä»¶**: {detail['output']}\n\n")
            if 'note' in detail:
                f.write(f"**å¤‡æ³¨**: {detail['note']}\n\n")
            if 'error' in detail:
                f.write(f"**é”™è¯¯ä¿¡æ¯**: {detail['error']}\n\n")
            f.write("---\n\n")
        
        f.write("## åŠŸèƒ½éªŒè¯\n\n")
        f.write("æœ¬æ¬¡æµ‹è¯•éªŒè¯äº†ä»¥ä¸‹æ ¸å¿ƒåŠŸèƒ½:\n\n")
        f.write("1. âœ… åŸºæœ¬æ–‡æ¡£ç”Ÿæˆæµç¨‹\n")
        f.write("2. âœ… å›¾ç‰‡å ä½ç¬¦å¤„ç†\n")
        f.write("3. âœ… å›¾ç‰‡é™„ä»¶è‡ªåŠ¨é™„åŠ \n")
        f.write("4. âœ… é”™è¯¯å¤„ç†å’Œç³»ç»Ÿå¥å£®æ€§\n")
        f.write("5. âœ… æ–‡æœ¬å’Œå›¾ç‰‡æ··åˆå¤„ç†\n\n")
        
        f.write("## ç»“è®º\n\n")
        if test_results['tests_failed'] == 0:
            f.write("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»ŸåŠŸèƒ½å®Œæ•´ï¼Œè¿è¡Œç¨³å®šã€‚\n")
        else:
            f.write(f"âš ï¸ å‘ç° {test_results['tests_failed']} ä¸ªé—®é¢˜ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚\n")
    
    logger.info(f"âœ… æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå®Œæˆ: {report_path}")


if __name__ == "__main__":
    # æ£€æŸ¥æ˜¯å¦è¦å¯åŠ¨Webç•Œé¢
    import sys
    if len(sys.argv) > 1 and sys.argv[1] == "--web":
        # å¯åŠ¨Webç•Œé¢
        import subprocess
        subprocess.run([sys.executable, "app.py"])
    elif len(sys.argv) > 1 and sys.argv[1] == "--cli":
        # å¯åŠ¨å‘½ä»¤è¡Œç•Œé¢
        main()
    else:
        # é»˜è®¤å¯åŠ¨Webç•Œé¢
        print("ğŸŒ å¯åŠ¨Webç•Œé¢...")
        print("å¦‚éœ€ä½¿ç”¨å‘½ä»¤è¡Œç‰ˆæœ¬ï¼Œè¯·è¿è¡Œ: python main.py --cli")
        print("=" * 50)
        import subprocess
        subprocess.run([sys.executable, "app.py"]) 